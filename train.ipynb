{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4fe1ec7",
   "metadata": {},
   "source": [
    "# Kaggle Dogs VS Cats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce542f",
   "metadata": {},
   "source": [
    "## Basic Lenet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0359724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    \n",
    "from tensorflow.keras import layers, callbacks, metrics, optimizers, models\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d26f4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogCatSequence(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, files_folder, files_list, batch_size):\n",
    "        if batch_size > len(files_list):\n",
    "            raise ValueError('Batch size is bigger than length of files list')\n",
    "            \n",
    "        self._files_list = files_list\n",
    "        self._batch_size = batch_size\n",
    "        self._files_folder = files_folder\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        end = min((index + 1) * self._batch_size, len(self._files_list) - 1)\n",
    "        batch_files_list = self._files_list[index * self._batch_size: end]\n",
    "\n",
    "        batch_x = np.array([io.imread(os.path.join(self._files_folder, filename)) for filename in batch_files_list])\n",
    "        batch_y = np.array([float(filename.startswith('dog')) for filename in batch_files_list])\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self._files_list) / self._batch_size))\n",
    "\n",
    "\n",
    "def f_score(ytrue, ypred, threshold=0.5, epsilon=10e-7):\n",
    "    # casting ytrue and ypred as float dtype\n",
    "    ytrue = tf.cast(ytrue, tf.float32)\n",
    "    ypred = tf.cast(ypred, tf.float32)\n",
    "\n",
    "    # setting values of ypred greater than the set threshold to 1 while those lesser to 0\n",
    "    ypred = tf.cast(tf.greater_equal(ypred, tf.constant(threshold)), tf.float32)\n",
    "\n",
    "    tp = tf.reduce_sum(ytrue*ypred) # calculating true positives\n",
    "    predicted_positive = tf.reduce_sum(ypred) # calculating predicted positives\n",
    "    actual_positive = tf.reduce_sum(ytrue) # calculating actual positives\n",
    "    \n",
    "    precision = tp/(predicted_positive+epsilon) # calculating precision\n",
    "    recall = tp/(actual_positive+epsilon) # calculating recall\n",
    "    \n",
    "    # calculating fbeta\n",
    "    fb = 2 * precision*recall / (precision + recall + epsilon)\n",
    "\n",
    "    return fb\n",
    "\n",
    "\n",
    "def print_errors(model, train_seq, test_seq):\n",
    "    train_f_score = model.evaluate(train_seq)[1]\n",
    "    test_f_score = model.evaluate(test_seq)[1]\n",
    "\n",
    "    print('train error = ', 1 - train_f_score)\n",
    "    print('test error = ', 1 - test_f_score)\n",
    "    \n",
    "    \n",
    "def train_model(model, trainin_sequence, validation_sequence):\n",
    "    model_check_point = callbacks.ModelCheckpoint(filepath='dogs_vs_cats_lenet5_weights_{epoch}.h5',\n",
    "                                              save_weights_only=True,\n",
    "                                              save_best_only=True,\n",
    "                                              monitor='val_loss',\n",
    "                                              mode='min',\n",
    "                                              verbose=True)\n",
    "\n",
    "    early_stopping = callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                            mode='min',\n",
    "                                            min_delta=10e-3,\n",
    "                                            verbose=True,\n",
    "                                            patience=30,\n",
    "                                            restore_best_weights=True)\n",
    "    \n",
    "    lr_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        verbose=True,\n",
    "        mode=\"min\",\n",
    "        min_delta=0.0001,\n",
    "        cooldown=0,\n",
    "        min_lr=0)\n",
    "\n",
    "\n",
    "\n",
    "    train_epochs = 100\n",
    "\n",
    "    train_callbacks = [model_check_point, early_stopping, lr_plateau]\n",
    "\n",
    "    model.fit(trainin_sequence, epochs=train_epochs, validation_data=validation_sequence, callbacks=train_callbacks)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def tune_model(model_func, train_sequence, validation_sequence):\n",
    "    hp = kt.HyperParameters()\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        model_func,\n",
    "        objective=\"val_loss\",\n",
    "        max_epochs=30,\n",
    "        hyperband_iterations=3,\n",
    "        factor=5,\n",
    "        directory='tuner',\n",
    "        project_name=str(model_func),\n",
    "    )\n",
    "\n",
    "    train_epochs = 10\n",
    "    tuner.search(train_sequence, epochs=train_epochs, validation_data=validation_sequence)\n",
    "    \n",
    "    return tuner\n",
    "\n",
    "def get_dataset_sequences(images_folder, batch_size):\n",
    "    images_list = sorted(os.listdir(images_folder))\n",
    "    random.seed(42)\n",
    "    random.shuffle(images_list)\n",
    "\n",
    "    train_part = 0.9\n",
    "    val_part = 0.05\n",
    "    test_part = 0.05\n",
    "\n",
    "    get_last_index = lambda part: int(part * len(images_list))\n",
    "\n",
    "    train_images_list = images_list[: get_last_index(train_part)]\n",
    "    val_images_list = images_list[get_last_index(train_part): get_last_index(train_part + val_part)]\n",
    "    test_images_list = images_list[get_last_index(train_part + val_part):\n",
    "                                       get_last_index(train_part + val_part + test_part)]\n",
    "    train_seq = DogCatSequence(images_folder, train_images_list, batch_size)\n",
    "    val_seq = DogCatSequence(images_folder, val_images_list, batch_size)\n",
    "    test_seq = DogCatSequence(images_folder, test_images_list, batch_size)\n",
    "    \n",
    "    return train_seq, val_seq, test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2893ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, val_seq, test_seq = get_dataset_sequences('train-64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973ddf5",
   "metadata": {},
   "source": [
    "## Basic Lenet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a1f607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet5_v1(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    nn = layers.Rescaling(1.0 / 255.0)(inputs)\n",
    "    nn = layers.Conv2D(filters=6, kernel_size=5, strides=(1, 1), activation='relu')(inputs)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "    nn = layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "    nn = layers.Flatten()(nn)\n",
    "    nn = layers.Dense(400, activation='relu')(nn)\n",
    "    nn = layers.Dense(120, activation='relu')(nn)\n",
    "    nn = layers.Dense(84, activation='relu')(nn)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(nn)\n",
    "    return models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8355bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lenet5_v1(train_seq[0][0].shape[1:])\n",
    "\n",
    "train_metrics = [f_score,\n",
    "                 metrics.Precision(thresholds=0.5),\n",
    "                 metrics.Recall(thresholds=0.5)]\n",
    "\n",
    "train_optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_loss = 'binary_crossentropy'\n",
    "\n",
    "model.compile(loss=train_loss,\n",
    "              optimizer=train_optimizer,\n",
    "              metrics=train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32331196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 1.4011 - f_score: 0.5428 - precision_1: 0.5430 - recall_1: 0.6137\n",
      "Epoch 1: val_loss improved from inf to 0.68042, saving model to dogs_vs_cats_lenet5_weights_1.h5\n",
      "352/352 [==============================] - 11s 29ms/step - loss: 1.3990 - f_score: 0.5430 - precision_1: 0.5430 - recall_1: 0.6139 - val_loss: 0.6804 - val_f_score: 0.5652 - val_precision_1: 0.5822 - val_recall_1: 0.5584\n",
      "Epoch 2/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.6473 - f_score: 0.6199 - precision_1: 0.6176 - recall_1: 0.6442\n",
      "Epoch 2: val_loss improved from 0.68042 to 0.65341, saving model to dogs_vs_cats_lenet5_weights_2.h5\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.6474 - f_score: 0.6202 - precision_1: 0.6180 - recall_1: 0.6447 - val_loss: 0.6534 - val_f_score: 0.6624 - val_precision_1: 0.5955 - val_recall_1: 0.7476\n",
      "Epoch 3/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.6033 - f_score: 0.6684 - precision_1: 0.6626 - recall_1: 0.6893\n",
      "Epoch 3: val_loss improved from 0.65341 to 0.64378, saving model to dogs_vs_cats_lenet5_weights_3.h5\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.6033 - f_score: 0.6684 - precision_1: 0.6626 - recall_1: 0.6893 - val_loss: 0.6438 - val_f_score: 0.6702 - val_precision_1: 0.6291 - val_recall_1: 0.7224\n",
      "Epoch 4/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.5366 - f_score: 0.7250 - precision_1: 0.7186 - recall_1: 0.7387\n",
      "Epoch 4: val_loss did not improve from 0.64378\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.5366 - f_score: 0.7250 - precision_1: 0.7186 - recall_1: 0.7387 - val_loss: 0.6653 - val_f_score: 0.6368 - val_precision_1: 0.6519 - val_recall_1: 0.6262\n",
      "Epoch 5/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.4584 - f_score: 0.7762 - precision_1: 0.7752 - recall_1: 0.7839\n",
      "Epoch 5: val_loss did not improve from 0.64378\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.4583 - f_score: 0.7761 - precision_1: 0.7752 - recall_1: 0.7839 - val_loss: 0.7434 - val_f_score: 0.6477 - val_precision_1: 0.6420 - val_recall_1: 0.6562\n",
      "Epoch 6/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3632 - f_score: 0.8310 - precision_1: 0.8365 - recall_1: 0.8307\n",
      "Epoch 6: val_loss did not improve from 0.64378\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.3632 - f_score: 0.8310 - precision_1: 0.8365 - recall_1: 0.8307 - val_loss: 0.8072 - val_f_score: 0.6457 - val_precision_1: 0.6343 - val_recall_1: 0.6593\n",
      "Epoch 7/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2775 - f_score: 0.8747 - precision_1: 0.8824 - recall_1: 0.8700\n",
      "Epoch 7: val_loss did not improve from 0.64378\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.2775 - f_score: 0.8747 - precision_1: 0.8824 - recall_1: 0.8700 - val_loss: 0.9918 - val_f_score: 0.6228 - val_precision_1: 0.6254 - val_recall_1: 0.6215\n",
      "Epoch 8/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2416 - f_score: 0.8948 - precision_1: 0.9024 - recall_1: 0.8910\n",
      "Epoch 8: val_loss did not improve from 0.64378\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.2416 - f_score: 0.8948 - precision_1: 0.9024 - recall_1: 0.8910 - val_loss: 1.0185 - val_f_score: 0.6347 - val_precision_1: 0.6655 - val_recall_1: 0.6057\n",
      "Epoch 9/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2049 - f_score: 0.9157 - precision_1: 0.9229 - recall_1: 0.9115\n",
      "Epoch 9: val_loss did not improve from 0.64378\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.2049 - f_score: 0.9157 - precision_1: 0.9229 - recall_1: 0.9115 - val_loss: 1.2297 - val_f_score: 0.6216 - val_precision_1: 0.6371 - val_recall_1: 0.6120\n",
      "Epoch 10/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1534 - f_score: 0.9382 - precision_1: 0.9434 - recall_1: 0.9356\n",
      "Epoch 10: val_loss did not improve from 0.64378\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.1534 - f_score: 0.9382 - precision_1: 0.9434 - recall_1: 0.9356 - val_loss: 1.5451 - val_f_score: 0.6012 - val_precision_1: 0.6491 - val_recall_1: 0.5631\n",
      "Epoch 11/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1407 - f_score: 0.9478 - precision_1: 0.9538 - recall_1: 0.9436\n",
      "Epoch 11: val_loss did not improve from 0.64378\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.1407 - f_score: 0.9478 - precision_1: 0.9538 - recall_1: 0.9436 - val_loss: 1.4477 - val_f_score: 0.6411 - val_precision_1: 0.6650 - val_recall_1: 0.6199\n",
      "Epoch 12/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1379 - f_score: 0.9502 - precision_1: 0.9557 - recall_1: 0.9465\n",
      "Epoch 12: val_loss did not improve from 0.64378\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.1382 - f_score: 0.9499 - precision_1: 0.9558 - recall_1: 0.9460 - val_loss: 1.5828 - val_f_score: 0.6341 - val_precision_1: 0.6684 - val_recall_1: 0.6041\n",
      "Epoch 12: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fa3a9944d00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2da1c13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 10s 27ms/step - loss: 0.5957 - f_score: 0.7138 - precision_1: 0.6439 - recall_1: 0.8072\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.6495 - f_score: 0.6705 - precision_1: 0.6068 - recall_1: 0.7595\n",
      "train error =  0.2862144112586975\n",
      "test error =  0.329542338848114\n"
     ]
    }
   ],
   "source": [
    "print_errors(model, train_seq, test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc47dfab",
   "metadata": {},
   "source": [
    "## Basic Lenet-5 with tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dc727ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet5_v2(hp):\n",
    "    \n",
    "    inputs = layers.Input(shape=(64, 64, 3))\n",
    "    nn = layers.Rescaling(1.0 / 255.0)(inputs)\n",
    "\n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_1', min_value=1, max_value=10, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(inputs)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_2', min_value=10, max_value=20, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "    \n",
    "    nn = layers.Flatten()(nn)\n",
    "\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_1', min_value=300, max_value=500, step=1), activation='relu')(nn)\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_2', min_value=50, max_value=120, step=1), activation='relu')(nn)\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_3', min_value=60, max_value=100, step=1), activation='relu')(nn)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(nn)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    train_metrics = [f_score,\n",
    "                     metrics.Precision(thresholds=0.5),\n",
    "                     metrics.Recall(thresholds=0.5)]\n",
    "\n",
    "    train_optimizer = optimizers.Adam(\n",
    "        learning_rate=hp.Float(name='learning_rate', min_value=10e-6, max_value=10e-4, sampling='log'))\n",
    "    train_loss = 'binary_crossentropy'\n",
    "\n",
    "    model.compile(loss=train_loss, optimizer=train_optimizer, metrics=train_metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb24963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26ce2d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 02m 32s]\n",
      "val_loss: 0.5534921884536743\n",
      "\n",
      "Best val_loss So Far: 0.515401303768158\n",
      "Total elapsed time: 00h 22m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = tune_model(lenet5_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40bc3870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.4684 - f_score: 0.7750 - precision: 0.7768 - recall: 0.7819\n",
      "Epoch 1: val_loss improved from inf to 0.50380, saving model to dogs_vs_cats_lenet5_weights_1.h5\n",
      "352/352 [==============================] - 11s 29ms/step - loss: 0.4685 - f_score: 0.7751 - precision: 0.7766 - recall: 0.7822 - val_loss: 0.5038 - val_f_score: 0.7344 - val_precision: 0.8192 - val_recall: 0.6719\n",
      "Epoch 2/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4109 - f_score: 0.8078 - precision: 0.8117 - recall: 0.8113\n",
      "Epoch 2: val_loss did not improve from 0.50380\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.4109 - f_score: 0.8078 - precision: 0.8117 - recall: 0.8113 - val_loss: 0.5213 - val_f_score: 0.7787 - val_precision: 0.7263 - val_recall: 0.8454\n",
      "Epoch 3/100\n",
      "350/352 [============================>.] - ETA: 0s - loss: 0.3421 - f_score: 0.8461 - precision: 0.8458 - recall: 0.8524\n",
      "Epoch 3: val_loss did not improve from 0.50380\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.3414 - f_score: 0.8467 - precision: 0.8463 - recall: 0.8532 - val_loss: 0.5323 - val_f_score: 0.7662 - val_precision: 0.7402 - val_recall: 0.8044\n",
      "Epoch 4/100\n",
      "350/352 [============================>.] - ETA: 0s - loss: 0.2354 - f_score: 0.9024 - precision: 0.9011 - recall: 0.9063\n",
      "Epoch 4: val_loss did not improve from 0.50380\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.2355 - f_score: 0.9023 - precision: 0.9007 - recall: 0.9063 - val_loss: 0.5708 - val_f_score: 0.7588 - val_precision: 0.7473 - val_recall: 0.7744\n",
      "Epoch 5/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1659 - f_score: 0.9347 - precision: 0.9322 - recall: 0.9397\n",
      "Epoch 5: val_loss did not improve from 0.50380\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.1666 - f_score: 0.9343 - precision: 0.9320 - recall: 0.9390 - val_loss: 0.6923 - val_f_score: 0.7287 - val_precision: 0.7754 - val_recall: 0.6972\n",
      "Epoch 6/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1210 - f_score: 0.9537 - precision: 0.9520 - recall: 0.9560\n",
      "Epoch 6: val_loss did not improve from 0.50380\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.1210 - f_score: 0.9537 - precision: 0.9520 - recall: 0.9560 - val_loss: 0.8316 - val_f_score: 0.7400 - val_precision: 0.7452 - val_recall: 0.7382\n",
      "Epoch 7/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0917 - f_score: 0.9664 - precision: 0.9666 - recall: 0.9672\n",
      "Epoch 7: val_loss did not improve from 0.50380\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.0917 - f_score: 0.9664 - precision: 0.9666 - recall: 0.9672 - val_loss: 0.9645 - val_f_score: 0.7504 - val_precision: 0.7415 - val_recall: 0.7603\n",
      "Epoch 8/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.0792 - f_score: 0.9718 - precision: 0.9712 - recall: 0.9734\n",
      "Epoch 8: val_loss did not improve from 0.50380\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.0792 - f_score: 0.9718 - precision: 0.9712 - recall: 0.9734 - val_loss: 1.0124 - val_f_score: 0.7519 - val_precision: 0.7831 - val_recall: 0.7287\n",
      "Epoch 9/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0814 - f_score: 0.9697 - precision: 0.9692 - recall: 0.9708\n",
      "Epoch 9: val_loss did not improve from 0.50380\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.0814 - f_score: 0.9697 - precision: 0.9692 - recall: 0.9708 - val_loss: 1.0356 - val_f_score: 0.7287 - val_precision: 0.7641 - val_recall: 0.7050\n",
      "Epoch 10/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.0560 - f_score: 0.9805 - precision: 0.9807 - recall: 0.9809\n",
      "Epoch 10: val_loss did not improve from 0.50380\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.0563 - f_score: 0.9803 - precision: 0.9807 - recall: 0.9806 - val_loss: 1.0238 - val_f_score: 0.7549 - val_precision: 0.7256 - val_recall: 0.7965\n",
      "Epoch 11/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.0668 - f_score: 0.9760 - precision: 0.9758 - recall: 0.9763\n",
      "Epoch 11: val_loss did not improve from 0.50380\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "352/352 [==============================] - 10s 28ms/step - loss: 0.0667 - f_score: 0.9760 - precision: 0.9759 - recall: 0.9762 - val_loss: 1.0474 - val_f_score: 0.7641 - val_precision: 0.7897 - val_recall: 0.7524\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "lenet5_v2_best_model = tuner.get_best_models()[0]\n",
    "lenet5_v2_best_model = train_model(lenet5_v2_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb6fdafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 10s 27ms/step - loss: 0.4086 - f_score: 0.8071 - precision: 0.8800 - recall: 0.7505\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.5472 - f_score: 0.6901 - precision: 0.7789 - recall: 0.6297\n",
      "train error =  0.1928519606590271\n",
      "test error =  0.3098623752593994\n"
     ]
    }
   ],
   "source": [
    "print_errors(lenet5_v2_best_model, train_seq, test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d032c6a",
   "metadata": {},
   "source": [
    "## Lenet-5 with additional conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aee38b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet5_v3(hp):\n",
    "    \n",
    "    inputs = layers.Input(shape=(64, 64, 3))\n",
    "    nn = layers.Rescaling(1.0 / 255.0)(inputs)\n",
    "\n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_1', min_value=1, max_value=20, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(inputs)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_2', min_value=10, max_value=30, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_3', min_value=20, max_value=40, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Flatten()(nn)\n",
    "\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_1', min_value=300, max_value=500, step=1), activation='relu')(nn)\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_2', min_value=50, max_value=120, step=1), activation='relu')(nn)\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_3', min_value=60, max_value=100, step=1), activation='relu')(nn)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(nn)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    train_metrics = [f_score,\n",
    "                     metrics.Precision(thresholds=0.5),\n",
    "                     metrics.Recall(thresholds=0.5)]\n",
    "\n",
    "    train_optimizer = optimizers.Adam(\n",
    "        learning_rate=hp.Float(name='learning_rate', min_value=10e-6, max_value=10e-4, sampling='log'))\n",
    "    train_loss = 'binary_crossentropy'\n",
    "\n",
    "    model.compile(loss=train_loss, optimizer=train_optimizer, metrics=train_metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48e8a2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 02m 34s]\n",
      "val_loss: 0.5273486375808716\n",
      "\n",
      "Best val_loss So Far: 0.4456341564655304\n",
      "Total elapsed time: 00h 29m 04s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = tune_model(lenet5_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b00a02cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.3684 - f_score: 0.8283 - precision: 0.8333 - recall: 0.8299\n",
      "Epoch 1: val_loss improved from inf to 0.43387, saving model to dogs_vs_cats_lenet5_weights_1.h5\n",
      "352/352 [==============================] - 11s 30ms/step - loss: 0.3684 - f_score: 0.8284 - precision: 0.8335 - recall: 0.8301 - val_loss: 0.4339 - val_f_score: 0.8081 - val_precision: 0.7725 - val_recall: 0.8517\n",
      "Epoch 2/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.3341 - f_score: 0.8490 - precision: 0.8499 - recall: 0.8529\n",
      "Epoch 2: val_loss did not improve from 0.43387\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.3345 - f_score: 0.8488 - precision: 0.8502 - recall: 0.8523 - val_loss: 0.4832 - val_f_score: 0.7683 - val_precision: 0.8349 - val_recall: 0.7177\n",
      "Epoch 3/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.3072 - f_score: 0.8629 - precision: 0.8626 - recall: 0.8686\n",
      "Epoch 3: val_loss did not improve from 0.43387\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.3070 - f_score: 0.8630 - precision: 0.8626 - recall: 0.8689 - val_loss: 0.4764 - val_f_score: 0.7952 - val_precision: 0.8255 - val_recall: 0.7760\n",
      "Epoch 4/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2640 - f_score: 0.8819 - precision: 0.8848 - recall: 0.8830\n",
      "Epoch 4: val_loss did not improve from 0.43387\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.2640 - f_score: 0.8819 - precision: 0.8848 - recall: 0.8830 - val_loss: 0.5443 - val_f_score: 0.7747 - val_precision: 0.8168 - val_recall: 0.7382\n",
      "Epoch 5/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2337 - f_score: 0.8992 - precision: 0.9002 - recall: 0.9019\n",
      "Epoch 5: val_loss did not improve from 0.43387\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.2335 - f_score: 0.8992 - precision: 0.9002 - recall: 0.9019 - val_loss: 0.5956 - val_f_score: 0.7604 - val_precision: 0.8702 - val_recall: 0.6767\n",
      "Epoch 6/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2135 - f_score: 0.9091 - precision: 0.9071 - recall: 0.9139\n",
      "Epoch 6: val_loss did not improve from 0.43387\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.2134 - f_score: 0.9091 - precision: 0.9071 - recall: 0.9139 - val_loss: 0.5727 - val_f_score: 0.7830 - val_precision: 0.7917 - val_recall: 0.7792\n",
      "Epoch 7/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1727 - f_score: 0.9274 - precision: 0.9289 - recall: 0.9282\n",
      "Epoch 7: val_loss did not improve from 0.43387\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.1727 - f_score: 0.9273 - precision: 0.9289 - recall: 0.9281 - val_loss: 0.6221 - val_f_score: 0.7859 - val_precision: 0.7889 - val_recall: 0.7839\n",
      "Epoch 8/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1679 - f_score: 0.9290 - precision: 0.9311 - recall: 0.9304\n",
      "Epoch 8: val_loss did not improve from 0.43387\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.1679 - f_score: 0.9290 - precision: 0.9311 - recall: 0.9304 - val_loss: 0.6539 - val_f_score: 0.7819 - val_precision: 0.8063 - val_recall: 0.7618\n",
      "Epoch 9/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1366 - f_score: 0.9450 - precision: 0.9448 - recall: 0.9474\n",
      "Epoch 9: val_loss did not improve from 0.43387\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.1369 - f_score: 0.9447 - precision: 0.9448 - recall: 0.9469 - val_loss: 0.8342 - val_f_score: 0.7273 - val_precision: 0.8520 - val_recall: 0.6356\n",
      "Epoch 10/100\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1232 - f_score: 0.9516 - precision: 0.9521 - recall: 0.9532\n",
      "Epoch 10: val_loss did not improve from 0.43387\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.1234 - f_score: 0.9516 - precision: 0.9521 - recall: 0.9532 - val_loss: 0.7854 - val_f_score: 0.7417 - val_precision: 0.8229 - val_recall: 0.6814\n",
      "Epoch 11/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1152 - f_score: 0.9544 - precision: 0.9552 - recall: 0.9550\n",
      "Epoch 11: val_loss did not improve from 0.43387\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "352/352 [==============================] - 10s 29ms/step - loss: 0.1152 - f_score: 0.9544 - precision: 0.9552 - recall: 0.9550 - val_loss: 0.9225 - val_f_score: 0.7254 - val_precision: 0.8441 - val_recall: 0.6404\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "lenet5_v3_best_model = tuner.get_best_models()[0]\n",
    "lenet5_v3_best_model = train_model(lenet5_v3_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08bb40b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 10s 27ms/step - loss: 0.3331 - f_score: 0.8587 - precision: 0.8155 - recall: 0.9109\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.4642 - f_score: 0.7864 - precision: 0.7400 - recall: 0.8465\n",
      "train error =  0.14125597476959229\n",
      "test error =  0.21361839771270752\n"
     ]
    }
   ],
   "source": [
    "print_errors(lenet5_v3_best_model, train_seq, test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c2fc7c",
   "metadata": {},
   "source": [
    "## Lenet5 with two additional conv layers and 128x128 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b437d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "train_seq, val_seq, test_seq = get_dataset_sequences('train-128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1595437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet5_v4(hp):\n",
    "    \n",
    "    inputs = layers.Input(shape=(128, 128, 3))\n",
    "    nn = layers.Rescaling(1.0 / 255.0)(inputs)\n",
    "\n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_1', min_value=1, max_value=20, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(inputs)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_2', min_value=20, max_value=40, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_3', min_value=40, max_value=60, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_4', min_value=60, max_value=80, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Flatten()(nn)\n",
    "\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_1', min_value=300, max_value=500, step=1), activation='relu')(nn)\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_2', min_value=80, max_value=120, step=1), activation='relu')(nn)\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_3', min_value=40, max_value=80, step=1), activation='relu')(nn)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(nn)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    train_metrics = [f_score,\n",
    "                     metrics.Precision(thresholds=0.5),\n",
    "                     metrics.Recall(thresholds=0.5)]\n",
    "\n",
    "    train_optimizer = optimizers.Adam(\n",
    "        learning_rate=hp.Float(name='learning_rate', min_value=10e-6, max_value=10e-4, sampling='log'))\n",
    "    train_loss = 'binary_crossentropy'\n",
    "\n",
    "    model.compile(loss=train_loss, optimizer=train_optimizer, metrics=train_metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4114194e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 07m 11s]\n",
      "val_loss: 0.38811683654785156\n",
      "\n",
      "Best val_loss So Far: 0.35724955797195435\n",
      "Total elapsed time: 01h 09m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = tune_model(lenet5_v4, train_seq, val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e1d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2491 - f_score: 0.8883 - precision: 0.8867 - recall: 0.8942\n",
      "Epoch 1: val_loss improved from inf to 0.33639, saving model to dogs_vs_cats_lenet5_weights_1.h5\n",
      "352/352 [==============================] - 28s 78ms/step - loss: 0.2491 - f_score: 0.8883 - precision: 0.8867 - recall: 0.8942 - val_loss: 0.3364 - val_f_score: 0.8575 - val_precision: 0.8460 - val_recall: 0.8754\n",
      "Epoch 2/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2141 - f_score: 0.9077 - precision: 0.9054 - recall: 0.9130\n",
      "Epoch 2: val_loss did not improve from 0.33639\n",
      "352/352 [==============================] - 27s 77ms/step - loss: 0.2141 - f_score: 0.9077 - precision: 0.9054 - recall: 0.9130 - val_loss: 0.4146 - val_f_score: 0.8201 - val_precision: 0.9074 - val_recall: 0.7571\n",
      "Epoch 3/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1729 - f_score: 0.9270 - precision: 0.9266 - recall: 0.9304\n",
      "Epoch 3: val_loss did not improve from 0.33639\n",
      "352/352 [==============================] - 27s 77ms/step - loss: 0.1729 - f_score: 0.9270 - precision: 0.9266 - recall: 0.9304 - val_loss: 0.3794 - val_f_score: 0.8401 - val_precision: 0.8189 - val_recall: 0.8628\n",
      "Epoch 4/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1561 - f_score: 0.9373 - precision: 0.9344 - recall: 0.9421\n",
      "Epoch 4: val_loss did not improve from 0.33639\n",
      "352/352 [==============================] - 27s 77ms/step - loss: 0.1561 - f_score: 0.9373 - precision: 0.9344 - recall: 0.9421 - val_loss: 0.4124 - val_f_score: 0.8451 - val_precision: 0.8476 - val_recall: 0.8423\n",
      "Epoch 5/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1333 - f_score: 0.9467 - precision: 0.9444 - recall: 0.9499\n",
      "Epoch 5: val_loss did not improve from 0.33639\n",
      "352/352 [==============================] - 27s 77ms/step - loss: 0.1333 - f_score: 0.9467 - precision: 0.9444 - recall: 0.9499 - val_loss: 0.4849 - val_f_score: 0.8418 - val_precision: 0.8548 - val_recall: 0.8360\n",
      "Epoch 6/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1153 - f_score: 0.9543 - precision: 0.9521 - recall: 0.9579\n",
      "Epoch 6: val_loss did not improve from 0.33639\n",
      "352/352 [==============================] - 27s 77ms/step - loss: 0.1153 - f_score: 0.9543 - precision: 0.9521 - recall: 0.9579 - val_loss: 0.4740 - val_f_score: 0.8514 - val_precision: 0.8192 - val_recall: 0.8864\n",
      "Epoch 7/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1012 - f_score: 0.9605 - precision: 0.9581 - recall: 0.9644\n",
      "Epoch 7: val_loss did not improve from 0.33639\n",
      "352/352 [==============================] - 27s 77ms/step - loss: 0.1012 - f_score: 0.9605 - precision: 0.9581 - recall: 0.9644 - val_loss: 0.4687 - val_f_score: 0.8489 - val_precision: 0.8893 - val_recall: 0.8107\n",
      "Epoch 8/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0836 - f_score: 0.9675 - precision: 0.9662 - recall: 0.9697\n",
      "Epoch 8: val_loss did not improve from 0.33639\n",
      "352/352 [==============================] - 27s 77ms/step - loss: 0.0836 - f_score: 0.9675 - precision: 0.9662 - recall: 0.9697 - val_loss: 0.4809 - val_f_score: 0.8623 - val_precision: 0.8380 - val_recall: 0.8896\n",
      "Epoch 9/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0817 - f_score: 0.9685 - precision: 0.9679 - recall: 0.9703\n",
      "Epoch 9: val_loss did not improve from 0.33639\n",
      "352/352 [==============================] - 27s 77ms/step - loss: 0.0817 - f_score: 0.9685 - precision: 0.9679 - recall: 0.9703 - val_loss: 0.5997 - val_f_score: 0.8382 - val_precision: 0.9053 - val_recall: 0.7839\n",
      "Epoch 10/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0780 - f_score: 0.9692 - precision: 0.9688 - recall: 0.9703\n",
      "Epoch 10: val_loss did not improve from 0.33639\n",
      "352/352 [==============================] - 27s 77ms/step - loss: 0.0780 - f_score: 0.9692 - precision: 0.9688 - recall: 0.9703 - val_loss: 0.5070 - val_f_score: 0.8481 - val_precision: 0.8549 - val_recall: 0.8454\n",
      "Epoch 11/100\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0710 - f_score: 0.9732 - precision: 0.9730 - recall: 0.9741\n",
      "Epoch 11: val_loss did not improve from 0.33639\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "352/352 [==============================] - 27s 77ms/step - loss: 0.0710 - f_score: 0.9732 - precision: 0.9730 - recall: 0.9741 - val_loss: 0.5563 - val_f_score: 0.8397 - val_precision: 0.8714 - val_recall: 0.8123\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "lenet5_v4_best_model = tuner.get_best_models()[0]\n",
    "lenet5_v4_best_model = train_model(lenet5_v4_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93d0d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 12s 34ms/step - loss: 0.2034 - f_score: 0.9171 - precision: 0.8970 - recall: 0.9409\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 0.3997 - f_score: 0.8284 - precision: 0.8120 - recall: 0.8544\n",
      "train error =  0.08293211460113525\n",
      "test error =  0.17155903577804565\n"
     ]
    }
   ],
   "source": [
    "print_errors(lenet5_v4_best_model, train_seq, test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff392b62",
   "metadata": {},
   "source": [
    "## Lenet5 with three additional conv layers and 256x256 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8718ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, val_seq, test_seq = get_dataset_sequences('train-256', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e677f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet5_v5(hp):\n",
    "    \n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "    nn = layers.Rescaling(1.0 / 255.0)(inputs)\n",
    "\n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_1', min_value=1, max_value=20, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(inputs)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_2', min_value=20, max_value=40, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_3', min_value=40, max_value=60, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "    \n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_4', min_value=60, max_value=80, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "    \n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_5', min_value=80, max_value=100, step=1),\n",
    "                        kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Flatten()(nn)\n",
    "\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_1', min_value=300, max_value=500, step=1), activation='relu')(nn)\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_2', min_value=80, max_value=120, step=1), activation='relu')(nn)\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_3', min_value=40, max_value=80, step=1), activation='relu')(nn)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(nn)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    train_metrics = [f_score,\n",
    "                     metrics.Precision(thresholds=0.5),\n",
    "                     metrics.Recall(thresholds=0.5)]\n",
    "\n",
    "    train_optimizer = optimizers.Adam(\n",
    "        learning_rate=hp.Float(name='learning_rate', min_value=10e-6, max_value=10e-4, sampling='log'))\n",
    "    train_loss = 'binary_crossentropy'\n",
    "\n",
    "    model.compile(loss=train_loss, optimizer=train_optimizer, metrics=train_metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b92dec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 31m 26s]\n",
      "val_loss: 0.22479461133480072\n",
      "\n",
      "Best val_loss So Far: 0.2145802527666092\n",
      "Total elapsed time: 04h 46m 47s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = tune_model(lenet5_v5, train_seq, val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42167506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.1142 - f_score: 0.9531 - precision: 0.9490 - recall: 0.9600\n",
      "Epoch 1: val_loss improved from inf to 0.22811, saving model to dogs_vs_cats_lenet5_weights_1.h5\n",
      "704/704 [==============================] - 91s 128ms/step - loss: 0.1142 - f_score: 0.9531 - precision: 0.9490 - recall: 0.9600 - val_loss: 0.2281 - val_f_score: 0.9051 - val_precision: 0.9121 - val_recall: 0.9006\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0986 - f_score: 0.9600 - precision: 0.9568 - recall: 0.9657\n",
      "Epoch 2: val_loss did not improve from 0.22811\n",
      "704/704 [==============================] - 90s 128ms/step - loss: 0.0986 - f_score: 0.9600 - precision: 0.9568 - recall: 0.9657 - val_loss: 0.2978 - val_f_score: 0.8880 - val_precision: 0.9324 - val_recall: 0.8486\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0851 - f_score: 0.9668 - precision: 0.9655 - recall: 0.9696\n",
      "Epoch 3: val_loss did not improve from 0.22811\n",
      "704/704 [==============================] - 90s 127ms/step - loss: 0.0851 - f_score: 0.9668 - precision: 0.9655 - recall: 0.9696 - val_loss: 0.2769 - val_f_score: 0.9103 - val_precision: 0.9184 - val_recall: 0.9054\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0761 - f_score: 0.9704 - precision: 0.9700 - recall: 0.9723\n",
      "Epoch 4: val_loss did not improve from 0.22811\n",
      "704/704 [==============================] - 90s 128ms/step - loss: 0.0761 - f_score: 0.9704 - precision: 0.9700 - recall: 0.9723 - val_loss: 0.3159 - val_f_score: 0.9091 - val_precision: 0.9195 - val_recall: 0.9006\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0595 - f_score: 0.9767 - precision: 0.9768 - recall: 0.9777\n",
      "Epoch 5: val_loss did not improve from 0.22811\n",
      "704/704 [==============================] - 90s 128ms/step - loss: 0.0595 - f_score: 0.9767 - precision: 0.9768 - recall: 0.9777 - val_loss: 0.3212 - val_f_score: 0.9050 - val_precision: 0.9091 - val_recall: 0.8991\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0664 - f_score: 0.9752 - precision: 0.9760 - recall: 0.9757\n",
      "Epoch 6: val_loss did not improve from 0.22811\n",
      "704/704 [==============================] - 90s 128ms/step - loss: 0.0664 - f_score: 0.9752 - precision: 0.9760 - recall: 0.9757 - val_loss: 0.3659 - val_f_score: 0.9175 - val_precision: 0.9102 - val_recall: 0.9274\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0483 - f_score: 0.9824 - precision: 0.9824 - recall: 0.9836\n",
      "Epoch 7: val_loss did not improve from 0.22811\n",
      "704/704 [==============================] - 90s 128ms/step - loss: 0.0483 - f_score: 0.9824 - precision: 0.9824 - recall: 0.9836 - val_loss: 0.5202 - val_f_score: 0.8841 - val_precision: 0.9336 - val_recall: 0.8423\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0524 - f_score: 0.9793 - precision: 0.9793 - recall: 0.9816\n",
      "Epoch 8: val_loss did not improve from 0.22811\n",
      "704/704 [==============================] - 90s 128ms/step - loss: 0.0524 - f_score: 0.9793 - precision: 0.9793 - recall: 0.9816 - val_loss: 0.3579 - val_f_score: 0.9260 - val_precision: 0.9231 - val_recall: 0.9274\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0480 - f_score: 0.9818 - precision: 0.9813 - recall: 0.9833\n",
      "Epoch 9: val_loss did not improve from 0.22811\n",
      "704/704 [==============================] - 90s 127ms/step - loss: 0.0480 - f_score: 0.9818 - precision: 0.9813 - recall: 0.9833 - val_loss: 0.3520 - val_f_score: 0.9215 - val_precision: 0.9174 - val_recall: 0.9290\n",
      "Epoch 10/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0426 - f_score: 0.9853 - precision: 0.9838 - recall: 0.9872\n",
      "Epoch 10: val_loss did not improve from 0.22811\n",
      "704/704 [==============================] - 90s 128ms/step - loss: 0.0426 - f_score: 0.9853 - precision: 0.9838 - recall: 0.9872 - val_loss: 0.3981 - val_f_score: 0.9194 - val_precision: 0.9171 - val_recall: 0.9243\n",
      "Epoch 11/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0450 - f_score: 0.9837 - precision: 0.9837 - recall: 0.9846\n",
      "Epoch 11: val_loss did not improve from 0.22811\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "704/704 [==============================] - 90s 127ms/step - loss: 0.0450 - f_score: 0.9837 - precision: 0.9837 - recall: 0.9846 - val_loss: 0.3774 - val_f_score: 0.9109 - val_precision: 0.8794 - val_recall: 0.9432\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "lenet5_v5_best_model = tuner.get_best_models()[0]\n",
    "lenet5_v5_best_model = train_model(lenet5_v5_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14829904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 36s 50ms/step - loss: 0.1089 - f_score: 0.9618 - precision: 0.9643 - recall: 0.9617\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.2571 - f_score: 0.8742 - precision: 0.8976 - recall: 0.9019\n",
      "train error =  0.038176119327545166\n",
      "test error =  0.12582576274871826\n"
     ]
    }
   ],
   "source": [
    "print_errors(tuner.get_best_models()[0], train_seq, test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53cdf34",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f961406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, val_seq, test_seq = get_dataset_sequences('train-256', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1236ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet():\n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "    \n",
    "    nn = layers.Conv2D(filters=96, kernel_size=11, strides=(4, 4), activation='relu')(inputs)\n",
    "    nn = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(nn)\n",
    "    \n",
    "    nn = layers.Conv2D(filters=256, kernel_size=5, strides=(4, 4), activation='relu', padding='same')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(nn)\n",
    "    \n",
    "    nn = layers.Conv2D(filters=384, kernel_size=3, activation='relu', padding='same')(nn)\n",
    "    nn = layers.Conv2D(filters=384, kernel_size=3, activation='relu', padding='same')(nn)\n",
    "    nn = layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(nn)\n",
    "    \n",
    "    nn = layers.Flatten()(nn)\n",
    "    \n",
    "    nn = layers.Dense(9216, activation='relu')(nn)\n",
    "    nn = layers.Dense(4096, activation='relu')(nn)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(nn)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    train_metrics = [f_score,\n",
    "                     metrics.Precision(thresholds=0.5),\n",
    "                     metrics.Recall(thresholds=0.5)]\n",
    "\n",
    "    train_optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    train_loss = 'binary_crossentropy'\n",
    "\n",
    "    model.compile(loss=train_loss, optimizer=train_optimizer, metrics=train_metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e9acd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 10:49:26.809639: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-07 10:49:26.809992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 10:49:26.810287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 10:49:26.810517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 10:49:27.283255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 10:49:27.283529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 10:49:27.283839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 10:49:27.284112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1339 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 750 Ti, pci bus id: 0000:01:00.0, compute capability: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 10:49:28.704984: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "2022-04-07 10:49:29.097740: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-07 10:49:29.217250: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 466.50MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-07 10:49:29.232329: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 358.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-07 10:49:29.232364: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 679.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-07 10:49:29.255494: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 466.50MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-07 10:49:29.385865: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 466.50MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-07 10:49:29.427312: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 358.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-07 10:49:29.427350: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 679.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-07 10:49:29.439526: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 340.21MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-07 10:49:29.470313: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 466.50MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011/1407 [====================>.........] - ETA: 31s - loss: 0.6741 - f_score: 0.5338 - precision: 0.5834 - recall: 0.6194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 10:50:49.390674: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 431.97MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - ETA: 0s - loss: 0.6529 - f_score: 0.5686 - precision: 0.6107 - recall: 0.6390\n",
      "Epoch 1: val_loss improved from inf to 0.55941, saving model to dogs_vs_cats_lenet5_weights_1.h5\n",
      "1407/1407 [==============================] - 116s 81ms/step - loss: 0.6529 - f_score: 0.5686 - precision: 0.6107 - recall: 0.6390 - val_loss: 0.5594 - val_f_score: 0.7275 - val_precision: 0.7617 - val_recall: 0.7161\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.5223 - f_score: 0.7328 - precision: 0.7412 - recall: 0.7569\n",
      "Epoch 2: val_loss improved from 0.55941 to 0.45884, saving model to dogs_vs_cats_lenet5_weights_2.h5\n",
      "1407/1407 [==============================] - 113s 80ms/step - loss: 0.5223 - f_score: 0.7328 - precision: 0.7412 - recall: 0.7569 - val_loss: 0.4588 - val_f_score: 0.7789 - val_precision: 0.8256 - val_recall: 0.7539\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.4359 - f_score: 0.7896 - precision: 0.7917 - recall: 0.8113\n",
      "Epoch 3: val_loss improved from 0.45884 to 0.42642, saving model to dogs_vs_cats_lenet5_weights_3.h5\n",
      "1407/1407 [==============================] - 113s 80ms/step - loss: 0.4359 - f_score: 0.7896 - precision: 0.7917 - recall: 0.8113 - val_loss: 0.4264 - val_f_score: 0.7756 - val_precision: 0.8745 - val_recall: 0.7145\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.3680 - f_score: 0.8254 - precision: 0.8330 - recall: 0.8387\n",
      "Epoch 4: val_loss did not improve from 0.42642\n",
      "1407/1407 [==============================] - 114s 81ms/step - loss: 0.3680 - f_score: 0.8254 - precision: 0.8330 - recall: 0.8387 - val_loss: 0.4610 - val_f_score: 0.7682 - val_precision: 0.9089 - val_recall: 0.6767\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.3052 - f_score: 0.8592 - precision: 0.8670 - recall: 0.8690\n",
      "Epoch 5: val_loss improved from 0.42642 to 0.40128, saving model to dogs_vs_cats_lenet5_weights_5.h5\n",
      "1407/1407 [==============================] - 116s 82ms/step - loss: 0.3052 - f_score: 0.8592 - precision: 0.8670 - recall: 0.8690 - val_loss: 0.4013 - val_f_score: 0.8160 - val_precision: 0.8347 - val_recall: 0.8123\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2491 - f_score: 0.8882 - precision: 0.8927 - recall: 0.8974\n",
      "Epoch 6: val_loss did not improve from 0.40128\n",
      "1407/1407 [==============================] - 114s 81ms/step - loss: 0.2491 - f_score: 0.8882 - precision: 0.8927 - recall: 0.8974 - val_loss: 0.4366 - val_f_score: 0.7895 - val_precision: 0.8538 - val_recall: 0.7461\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.2033 - f_score: 0.9112 - precision: 0.9144 - recall: 0.9189\n",
      "Epoch 7: val_loss did not improve from 0.40128\n",
      "1407/1407 [==============================] - 111s 79ms/step - loss: 0.2033 - f_score: 0.9112 - precision: 0.9144 - recall: 0.9189 - val_loss: 0.5437 - val_f_score: 0.8074 - val_precision: 0.8429 - val_recall: 0.7871\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1621 - f_score: 0.9312 - precision: 0.9356 - recall: 0.9348\n",
      "Epoch 8: val_loss did not improve from 0.40128\n",
      "1407/1407 [==============================] - 111s 79ms/step - loss: 0.1621 - f_score: 0.9312 - precision: 0.9356 - recall: 0.9348 - val_loss: 0.5683 - val_f_score: 0.8077 - val_precision: 0.8389 - val_recall: 0.7886\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1308 - f_score: 0.9441 - precision: 0.9450 - recall: 0.9506\n",
      "Epoch 9: val_loss did not improve from 0.40128\n",
      "1407/1407 [==============================] - 111s 79ms/step - loss: 0.1308 - f_score: 0.9441 - precision: 0.9450 - recall: 0.9506 - val_loss: 0.5275 - val_f_score: 0.8212 - val_precision: 0.7959 - val_recall: 0.8612\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.1043 - f_score: 0.9572 - precision: 0.9572 - recall: 0.9625\n",
      "Epoch 10: val_loss did not improve from 0.40128\n",
      "1407/1407 [==============================] - 115s 82ms/step - loss: 0.1043 - f_score: 0.9572 - precision: 0.9572 - recall: 0.9625 - val_loss: 0.5305 - val_f_score: 0.8186 - val_precision: 0.8193 - val_recall: 0.8297\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0959 - f_score: 0.9616 - precision: 0.9626 - recall: 0.9659\n",
      "Epoch 11: val_loss did not improve from 0.40128\n",
      "1407/1407 [==============================] - 115s 82ms/step - loss: 0.0959 - f_score: 0.9616 - precision: 0.9626 - recall: 0.9659 - val_loss: 0.5546 - val_f_score: 0.8024 - val_precision: 0.8615 - val_recall: 0.7650\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0768 - f_score: 0.9705 - precision: 0.9731 - recall: 0.9724\n",
      "Epoch 12: val_loss did not improve from 0.40128\n",
      "1407/1407 [==============================] - 114s 81ms/step - loss: 0.0768 - f_score: 0.9705 - precision: 0.9731 - recall: 0.9724 - val_loss: 0.6490 - val_f_score: 0.7933 - val_precision: 0.8526 - val_recall: 0.7571\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0769 - f_score: 0.9695 - precision: 0.9713 - recall: 0.9722\n",
      "Epoch 13: val_loss did not improve from 0.40128\n",
      "1407/1407 [==============================] - 114s 81ms/step - loss: 0.0769 - f_score: 0.9695 - precision: 0.9713 - recall: 0.9722 - val_loss: 0.7557 - val_f_score: 0.8260 - val_precision: 0.7859 - val_recall: 0.8801\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0683 - f_score: 0.9732 - precision: 0.9742 - recall: 0.9759\n",
      "Epoch 14: val_loss did not improve from 0.40128\n",
      "1407/1407 [==============================] - 114s 81ms/step - loss: 0.0683 - f_score: 0.9732 - precision: 0.9742 - recall: 0.9759 - val_loss: 0.7947 - val_f_score: 0.7959 - val_precision: 0.8482 - val_recall: 0.7666\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0618 - f_score: 0.9769 - precision: 0.9773 - recall: 0.9788\n",
      "Epoch 15: val_loss did not improve from 0.40128\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "1407/1407 [==============================] - 112s 79ms/step - loss: 0.0618 - f_score: 0.9769 - precision: 0.9773 - recall: 0.9788 - val_loss: 0.8763 - val_f_score: 0.8176 - val_precision: 0.8547 - val_recall: 0.7981\n",
      "Epoch 15: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fba1452daf0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = alexnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_seq, val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd08ce45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 33s 24ms/step - loss: 0.2157 - f_score: 0.9120 - precision: 0.9126 - recall: 0.9225\n",
      "79/79 [==============================] - 2s 23ms/step - loss: 0.4582 - f_score: 0.7696 - precision: 0.7931 - recall: 0.8006\n",
      "train error =  0.08798092603683472\n",
      "test error =  0.2304016351699829\n"
     ]
    }
   ],
   "source": [
    "print_errors(model, train_seq, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5c5bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet_v2(hp):\n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_1', min_value=1, max_value=100, step=1),\n",
    "                       kernel_size=11, strides=(4, 4), activation='relu')(inputs)\n",
    "    nn = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(nn)\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_2', min_value=200, max_value=300, step=1),\n",
    "                       kernel_size=5, strides=(4, 4), activation='relu', padding='same')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(nn)\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_3', min_value=300, max_value=400, step=1),\n",
    "                       kernel_size=3, activation='relu', padding='same')(nn)\n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_4', min_value=300, max_value=400, step=1),\n",
    "                       kernel_size=3, activation='relu', padding='same')(nn)\n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_5', min_value=200, max_value=300, step=1),\n",
    "                       kernel_size=3, activation='relu', padding='same')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(nn)\n",
    "    \n",
    "    nn = layers.Flatten()(nn)\n",
    "    \n",
    "    nn = layers.Dense(hp.Int(name='dense_1', min_value=2000, max_value=10000, step=50), \n",
    "                      activation='relu')(nn)\n",
    "    nn = layers.Dense(hp.Int(name='dense_2', min_value=2000, max_value=5000, step=50), activation='relu')(nn)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(nn)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    train_metrics = [f_score,\n",
    "                     metrics.Precision(thresholds=0.5),\n",
    "                     metrics.Recall(thresholds=0.5)]\n",
    "\n",
    "    train_optimizer = optimizers.Adam(\n",
    "        learning_rate=hp.Float(name='learning_rate', min_value=10e-6, max_value=10e-4, sampling='log'))\n",
    "    train_loss = 'binary_crossentropy'\n",
    "\n",
    "    model.compile(loss=train_loss, optimizer=train_optimizer, metrics=train_metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdcb22c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 112 Complete [00h 04m 36s]\n",
      "val_loss: 0.5043529272079468\n",
      "\n",
      "Best val_loss So Far: 0.3775126039981842\n",
      "Total elapsed time: 12h 12m 12s\n",
      "\n",
      "Search: Running Trial #113\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "43                |81                |filters_conv_1\n",
      "292               |267               |filters_conv_2\n",
      "350               |357               |filters_conv_3\n",
      "366               |349               |filters_conv_4\n",
      "280               |262               |filters_conv_5\n",
      "4650              |5000              |dense_1\n",
      "2350              |4950              |dense_2\n",
      "0.00011628        |5.5126e-05        |learning_rate\n",
      "30                |30                |tuner/epochs\n",
      "6                 |6                 |tuner/initial_epoch\n",
      "1                 |2                 |tuner/bracket\n",
      "1                 |2                 |tuner/round\n",
      "0106              |0034              |tuner/trial_id\n",
      "\n",
      "Epoch 7/30\n",
      "   5/1407 [..............................] - ETA: 1:04 - loss: 3.9868 - f_score: 0.2435 - precision: 0.4375 - recall: 0.4242WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0227s vs `on_train_batch_end` time: 0.0243s). Check your callbacks.\n",
      "1407/1407 [==============================] - 69s 48ms/step - loss: 0.6465 - f_score: 0.5905 - precision: 0.6299 - recall: 0.6468 - val_loss: 0.5538 - val_f_score: 0.7676 - val_precision: 0.6543 - val_recall: 0.9432\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 68s 48ms/step - loss: 0.5047 - f_score: 0.7416 - precision: 0.7495 - recall: 0.7667 - val_loss: 0.4435 - val_f_score: 0.8003 - val_precision: 0.7466 - val_recall: 0.8738\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 68s 48ms/step - loss: 0.4254 - f_score: 0.7952 - precision: 0.7975 - recall: 0.8178 - val_loss: 0.4330 - val_f_score: 0.7874 - val_precision: 0.8500 - val_recall: 0.7508\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 67s 48ms/step - loss: 0.3579 - f_score: 0.8342 - precision: 0.8353 - recall: 0.8532 - val_loss: 0.4389 - val_f_score: 0.7412 - val_precision: 0.8806 - val_recall: 0.6861\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 68s 48ms/step - loss: 0.3040 - f_score: 0.8612 - precision: 0.8632 - recall: 0.8761 - val_loss: 0.4243 - val_f_score: 0.7997 - val_precision: 0.8473 - val_recall: 0.7792\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 67s 48ms/step - loss: 0.2473 - f_score: 0.8878 - precision: 0.8919 - recall: 0.8983 - val_loss: 0.4566 - val_f_score: 0.7430 - val_precision: 0.8712 - val_recall: 0.6830\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 67s 48ms/step - loss: 0.2006 - f_score: 0.9135 - precision: 0.9151 - recall: 0.9233 - val_loss: 0.5277 - val_f_score: 0.7889 - val_precision: 0.8597 - val_recall: 0.7445\n",
      "Epoch 14/30\n",
      "1407/1407 [==============================] - 68s 48ms/step - loss: 0.1596 - f_score: 0.9300 - precision: 0.9350 - recall: 0.9342 - val_loss: 0.5763 - val_f_score: 0.8025 - val_precision: 0.7734 - val_recall: 0.8722\n",
      "Epoch 15/30\n",
      "   9/1407 [..............................] - ETA: 1:08 - loss: 0.1844 - f_score: 0.9101 - precision: 0.8630 - recall: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner \u001b[38;5;241m=\u001b[39m \u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43malexnet_v2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_seq\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mtune_model\u001b[0;34m(model_func, train_sequence, validation_sequence)\u001b[0m\n\u001b[1;32m     80\u001b[0m tuner \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mHyperband(\n\u001b[1;32m     81\u001b[0m     model_func,\n\u001b[1;32m     82\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(model_func),\n\u001b[1;32m     88\u001b[0m )\n\u001b[1;32m     90\u001b[0m train_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 91\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tuner\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 179\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras_tuner/tuners/hyperband.py:384\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    383\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHyperband\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:294\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    293\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 294\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    221\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 222\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tuner_utils\u001b[38;5;241m.\u001b[39mconvert_to_metrics_dict(\n\u001b[1;32m    224\u001b[0m     results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperModel.fit()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:137\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1389\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras/callbacks.py:353\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    351\u001b[0m   start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 353\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_batch_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras/callbacks.py:272\u001b[0m, in \u001b[0;36mCallbackList._process_logs\u001b[0;34m(self, logs, is_batch_hook)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_batch_hook \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_hooks_support_tf_logs:\n\u001b[1;32m    271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m logs\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    555\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 557\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner = tune_model(alexnet_v2, train_seq, val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72080c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_v2_best_model = tuner.get_best_models()[0]\n",
    "print_errors(alexnet_v2_best_model, train_seq, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4fdc20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0948 - f_score: 0.9602 - precision: 0.9640 - recall: 0.9618\n",
      "Epoch 1: val_loss improved from inf to 0.95002, saving model to dogs_vs_cats_lenet5_weights_1.h5\n",
      "1407/1407 [==============================] - 84s 60ms/step - loss: 0.0948 - f_score: 0.9602 - precision: 0.9640 - recall: 0.9618 - val_loss: 0.9500 - val_f_score: 0.7298 - val_precision: 0.8947 - val_recall: 0.6435\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0813 - f_score: 0.9676 - precision: 0.9699 - recall: 0.9695\n",
      "Epoch 2: val_loss improved from 0.95002 to 0.61500, saving model to dogs_vs_cats_lenet5_weights_2.h5\n",
      "1407/1407 [==============================] - 84s 60ms/step - loss: 0.0813 - f_score: 0.9676 - precision: 0.9699 - recall: 0.9695 - val_loss: 0.6150 - val_f_score: 0.8223 - val_precision: 0.7911 - val_recall: 0.8722\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0715 - f_score: 0.9712 - precision: 0.9731 - recall: 0.9730\n",
      "Epoch 3: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 83s 59ms/step - loss: 0.0715 - f_score: 0.9712 - precision: 0.9731 - recall: 0.9730 - val_loss: 0.8254 - val_f_score: 0.8245 - val_precision: 0.8225 - val_recall: 0.8407\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0655 - f_score: 0.9743 - precision: 0.9751 - recall: 0.9771\n",
      "Epoch 4: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 84s 59ms/step - loss: 0.0655 - f_score: 0.9743 - precision: 0.9751 - recall: 0.9771 - val_loss: 0.8282 - val_f_score: 0.8296 - val_precision: 0.8049 - val_recall: 0.8722\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0586 - f_score: 0.9773 - precision: 0.9784 - recall: 0.9795\n",
      "Epoch 5: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 83s 59ms/step - loss: 0.0586 - f_score: 0.9773 - precision: 0.9784 - recall: 0.9795 - val_loss: 0.7245 - val_f_score: 0.8133 - val_precision: 0.8497 - val_recall: 0.7934\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0527 - f_score: 0.9798 - precision: 0.9795 - recall: 0.9828\n",
      "Epoch 6: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 83s 59ms/step - loss: 0.0527 - f_score: 0.9798 - precision: 0.9795 - recall: 0.9828 - val_loss: 0.8786 - val_f_score: 0.8043 - val_precision: 0.8228 - val_recall: 0.7981\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0481 - f_score: 0.9816 - precision: 0.9806 - recall: 0.9850\n",
      "Epoch 7: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 84s 60ms/step - loss: 0.0481 - f_score: 0.9816 - precision: 0.9806 - recall: 0.9850 - val_loss: 1.1460 - val_f_score: 0.7685 - val_precision: 0.8691 - val_recall: 0.7224\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0492 - f_score: 0.9819 - precision: 0.9835 - recall: 0.9818\n",
      "Epoch 8: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 87s 62ms/step - loss: 0.0492 - f_score: 0.9819 - precision: 0.9835 - recall: 0.9818 - val_loss: 0.7092 - val_f_score: 0.8195 - val_precision: 0.8347 - val_recall: 0.8123\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0447 - f_score: 0.9838 - precision: 0.9830 - recall: 0.9856\n",
      "Epoch 9: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 88s 63ms/step - loss: 0.0447 - f_score: 0.9838 - precision: 0.9830 - recall: 0.9856 - val_loss: 0.8399 - val_f_score: 0.7929 - val_precision: 0.8504 - val_recall: 0.7713\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0390 - f_score: 0.9858 - precision: 0.9853 - recall: 0.9875\n",
      "Epoch 10: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 88s 63ms/step - loss: 0.0390 - f_score: 0.9858 - precision: 0.9853 - recall: 0.9875 - val_loss: 1.0496 - val_f_score: 0.7980 - val_precision: 0.8250 - val_recall: 0.8107\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0399 - f_score: 0.9861 - precision: 0.9853 - recall: 0.9878\n",
      "Epoch 11: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 88s 63ms/step - loss: 0.0399 - f_score: 0.9861 - precision: 0.9853 - recall: 0.9878 - val_loss: 0.8162 - val_f_score: 0.7904 - val_precision: 0.8333 - val_recall: 0.7886\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0360 - f_score: 0.9867 - precision: 0.9873 - recall: 0.9873\n",
      "Epoch 12: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 88s 62ms/step - loss: 0.0360 - f_score: 0.9867 - precision: 0.9873 - recall: 0.9873 - val_loss: 1.0176 - val_f_score: 0.8239 - val_precision: 0.8083 - val_recall: 0.8580\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0362 - f_score: 0.9861 - precision: 0.9869 - recall: 0.9878\n",
      "Epoch 13: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 88s 63ms/step - loss: 0.0362 - f_score: 0.9861 - precision: 0.9869 - recall: 0.9878 - val_loss: 0.8993 - val_f_score: 0.7985 - val_precision: 0.8099 - val_recall: 0.8265\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0387 - f_score: 0.9851 - precision: 0.9853 - recall: 0.9871\n",
      "Epoch 14: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 88s 63ms/step - loss: 0.0387 - f_score: 0.9851 - precision: 0.9853 - recall: 0.9871 - val_loss: 1.0642 - val_f_score: 0.8206 - val_precision: 0.7712 - val_recall: 0.8880\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0324 - f_score: 0.9882 - precision: 0.9882 - recall: 0.9893\n",
      "Epoch 15: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 88s 63ms/step - loss: 0.0324 - f_score: 0.9882 - precision: 0.9882 - recall: 0.9893 - val_loss: 1.3015 - val_f_score: 0.8098 - val_precision: 0.7605 - val_recall: 0.8817\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0319 - f_score: 0.9899 - precision: 0.9897 - recall: 0.9907\n",
      "Epoch 16: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 88s 62ms/step - loss: 0.0319 - f_score: 0.9899 - precision: 0.9897 - recall: 0.9907 - val_loss: 0.9877 - val_f_score: 0.8159 - val_precision: 0.8591 - val_recall: 0.7886\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0294 - f_score: 0.9894 - precision: 0.9901 - recall: 0.9896\n",
      "Epoch 17: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 88s 63ms/step - loss: 0.0294 - f_score: 0.9894 - precision: 0.9901 - recall: 0.9896 - val_loss: 1.2462 - val_f_score: 0.8084 - val_precision: 0.8366 - val_recall: 0.8155\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0289 - f_score: 0.9895 - precision: 0.9896 - recall: 0.9914\n",
      "Epoch 18: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 88s 62ms/step - loss: 0.0289 - f_score: 0.9895 - precision: 0.9896 - recall: 0.9914 - val_loss: 1.0998 - val_f_score: 0.8184 - val_precision: 0.8082 - val_recall: 0.8375\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0304 - f_score: 0.9899 - precision: 0.9904 - recall: 0.9910\n",
      "Epoch 19: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 81s 57ms/step - loss: 0.0304 - f_score: 0.9899 - precision: 0.9904 - recall: 0.9910 - val_loss: 0.8754 - val_f_score: 0.8312 - val_precision: 0.8233 - val_recall: 0.8454\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0299 - f_score: 0.9893 - precision: 0.9898 - recall: 0.9897\n",
      "Epoch 20: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 85s 60ms/step - loss: 0.0299 - f_score: 0.9893 - precision: 0.9898 - recall: 0.9897 - val_loss: 1.1377 - val_f_score: 0.8127 - val_precision: 0.8276 - val_recall: 0.8328\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0259 - f_score: 0.9909 - precision: 0.9909 - recall: 0.9914\n",
      "Epoch 21: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 85s 61ms/step - loss: 0.0259 - f_score: 0.9909 - precision: 0.9909 - recall: 0.9914 - val_loss: 1.0555 - val_f_score: 0.7817 - val_precision: 0.8188 - val_recall: 0.7839\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0299 - f_score: 0.9900 - precision: 0.9916 - recall: 0.9906\n",
      "Epoch 22: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 85s 61ms/step - loss: 0.0299 - f_score: 0.9900 - precision: 0.9916 - recall: 0.9906 - val_loss: 1.0642 - val_f_score: 0.8058 - val_precision: 0.7699 - val_recall: 0.8864\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0262 - f_score: 0.9913 - precision: 0.9923 - recall: 0.9915\n",
      "Epoch 23: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 86s 61ms/step - loss: 0.0262 - f_score: 0.9913 - precision: 0.9923 - recall: 0.9915 - val_loss: 0.8365 - val_f_score: 0.8232 - val_precision: 0.8179 - val_recall: 0.8360\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0240 - f_score: 0.9923 - precision: 0.9933 - recall: 0.9921\n",
      "Epoch 24: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 85s 61ms/step - loss: 0.0240 - f_score: 0.9923 - precision: 0.9933 - recall: 0.9921 - val_loss: 1.0927 - val_f_score: 0.7906 - val_precision: 0.8571 - val_recall: 0.7476\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0249 - f_score: 0.9910 - precision: 0.9920 - recall: 0.9917\n",
      "Epoch 25: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 85s 61ms/step - loss: 0.0249 - f_score: 0.9910 - precision: 0.9920 - recall: 0.9917 - val_loss: 1.2110 - val_f_score: 0.8280 - val_precision: 0.8550 - val_recall: 0.8186\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0212 - f_score: 0.9923 - precision: 0.9934 - recall: 0.9923\n",
      "Epoch 26: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 85s 60ms/step - loss: 0.0212 - f_score: 0.9923 - precision: 0.9934 - recall: 0.9923 - val_loss: 1.2023 - val_f_score: 0.8087 - val_precision: 0.8320 - val_recall: 0.8202\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0227 - f_score: 0.9923 - precision: 0.9914 - recall: 0.9939\n",
      "Epoch 27: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 85s 60ms/step - loss: 0.0227 - f_score: 0.9923 - precision: 0.9914 - recall: 0.9939 - val_loss: 1.1371 - val_f_score: 0.8083 - val_precision: 0.8131 - val_recall: 0.8438\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0229 - f_score: 0.9924 - precision: 0.9934 - recall: 0.9923\n",
      "Epoch 28: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 85s 60ms/step - loss: 0.0229 - f_score: 0.9924 - precision: 0.9934 - recall: 0.9923 - val_loss: 1.0298 - val_f_score: 0.8226 - val_precision: 0.8344 - val_recall: 0.8502\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0184 - f_score: 0.9938 - precision: 0.9943 - recall: 0.9936\n",
      "Epoch 29: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 85s 60ms/step - loss: 0.0184 - f_score: 0.9938 - precision: 0.9943 - recall: 0.9936 - val_loss: 1.0684 - val_f_score: 0.8276 - val_precision: 0.8133 - val_recall: 0.8517\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0220 - f_score: 0.9925 - precision: 0.9922 - recall: 0.9931\n",
      "Epoch 30: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 84s 59ms/step - loss: 0.0220 - f_score: 0.9925 - precision: 0.9922 - recall: 0.9931 - val_loss: 1.1367 - val_f_score: 0.8283 - val_precision: 0.7980 - val_recall: 0.8722\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0221 - f_score: 0.9931 - precision: 0.9929 - recall: 0.9936\n",
      "Epoch 31: val_loss did not improve from 0.61500\n",
      "1407/1407 [==============================] - 86s 61ms/step - loss: 0.0221 - f_score: 0.9931 - precision: 0.9929 - recall: 0.9936 - val_loss: 1.3615 - val_f_score: 0.8034 - val_precision: 0.8380 - val_recall: 0.8076\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0167 - f_score: 0.9936 - precision: 0.9938 - recall: 0.9943\n",
      "Epoch 32: val_loss did not improve from 0.61500\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "1407/1407 [==============================] - 85s 60ms/step - loss: 0.0167 - f_score: 0.9936 - precision: 0.9938 - recall: 0.9943 - val_loss: 1.4381 - val_f_score: 0.8226 - val_precision: 0.8276 - val_recall: 0.8328\n",
      "Epoch 32: early stopping\n",
      "1407/1407 [==============================] - 29s 20ms/step - loss: 0.0730 - f_score: 0.9701 - precision: 0.9542 - recall: 0.9910\n",
      "79/79 [==============================] - 2s 20ms/step - loss: 0.7926 - f_score: 0.7751 - precision: 0.7572 - recall: 0.8339\n",
      "train error =  0.02990281581878662\n",
      "test error =  0.22493183612823486\n"
     ]
    }
   ],
   "source": [
    "alexnet_v2_best_model_trained = train_model(alexnet_v2_best_model, train_seq, val_seq)\n",
    "print_errors(alexnet_v2_best_model_trained, train_seq, test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6792f180",
   "metadata": {},
   "source": [
    "## Lenet5 v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7af985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet5_v6(hp):\n",
    "    \n",
    "    inputs = layers.Input(shape=(256, 256, 3))\n",
    "    nn = layers.Rescaling(1.0 / 255.0)(inputs)\n",
    "\n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_1', min_value=1, max_value=20, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(inputs)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_2', min_value=20, max_value=40, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_3', min_value=40, max_value=60, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu', padding='same')(nn)\n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_4', min_value=40, max_value=60, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "    \n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_5', min_value=60, max_value=80, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu', padding='same')(nn)\n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_6', min_value=60, max_value=80, step=1),\n",
    "                       kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "    \n",
    "    \n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_7', min_value=80, max_value=100, step=1),\n",
    "                        kernel_size=5, strides=(1, 1), activation='relu', padding='same')(nn)\n",
    "    nn = layers.Conv2D(filters=hp.Int(name='filters_conv_7', min_value=80, max_value=100, step=1),\n",
    "                        kernel_size=5, strides=(1, 1), activation='relu')(nn)\n",
    "    nn = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(nn)\n",
    "\n",
    "    \n",
    "    nn = layers.Flatten()(nn)\n",
    "\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_1', min_value=300, max_value=500, step=1), activation='relu')(nn)\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_2', min_value=80, max_value=120, step=1), activation='relu')(nn)\n",
    "    nn = layers.Dense(hp.Int(name='units_dense_3', min_value=40, max_value=80, step=1), activation='relu')(nn)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(nn)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    train_metrics = [f_score,\n",
    "                     metrics.Precision(thresholds=0.5),\n",
    "                     metrics.Recall(thresholds=0.5)]\n",
    "\n",
    "    train_optimizer = optimizers.Adam(\n",
    "        learning_rate=hp.Float(name='learning_rate', min_value=10e-6, max_value=10e-4, sampling='log'))\n",
    "    train_loss = 'binary_crossentropy'\n",
    "\n",
    "    model.compile(loss=train_loss, optimizer=train_optimizer, metrics=train_metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49be4806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 104 Complete [00h 19m 24s]\n",
      "val_loss: 0.27580711245536804\n",
      "\n",
      "Best val_loss So Far: 0.16066938638687134\n",
      "Total elapsed time: 22h 44m 35s\n",
      "\n",
      "Search: Running Trial #105\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "18                |8                 |filters_conv_1\n",
      "31                |36                |filters_conv_2\n",
      "48                |49                |filters_conv_3\n",
      "51                |46                |filters_conv_4\n",
      "68                |72                |filters_conv_5\n",
      "63                |78                |filters_conv_6\n",
      "85                |81                |filters_conv_7\n",
      "339               |399               |units_dense_1\n",
      "80                |88                |units_dense_2\n",
      "47                |58                |units_dense_3\n",
      "5.7848e-05        |0.00017896        |learning_rate\n",
      "6                 |30                |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "1                 |0                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/6\n",
      "1407/1407 [==============================] - 189s 133ms/step - loss: 0.6322 - f_score: 0.6093 - precision: 0.6256 - recall: 0.6607 - val_loss: 0.5770 - val_f_score: 0.6863 - val_precision: 0.6888 - val_recall: 0.7050\n",
      "Epoch 2/6\n",
      "1407/1407 [==============================] - 188s 133ms/step - loss: 0.5197 - f_score: 0.7357 - precision: 0.7344 - recall: 0.7629 - val_loss: 0.4637 - val_f_score: 0.7814 - val_precision: 0.7955 - val_recall: 0.7792\n",
      "Epoch 3/6\n",
      " 735/1407 [==============>...............] - ETA: 1:27 - loss: 0.4487 - f_score: 0.7812 - precision: 0.7860 - recall: 0.8042"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner \u001b[38;5;241m=\u001b[39m \u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlenet5_v6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_seq\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mtune_model\u001b[0;34m(model_func, train_sequence, validation_sequence)\u001b[0m\n\u001b[1;32m     80\u001b[0m tuner \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mHyperband(\n\u001b[1;32m     81\u001b[0m     model_func,\n\u001b[1;32m     82\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(model_func),\n\u001b[1;32m     88\u001b[0m )\n\u001b[1;32m     90\u001b[0m train_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 91\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tuner\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 179\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras_tuner/tuners/hyperband.py:384\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    383\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHyperband\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:294\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    293\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 294\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    221\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 222\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tuner_utils\u001b[38;5;241m.\u001b[39mconvert_to_metrics_dict(\n\u001b[1;32m    224\u001b[0m     results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperModel.fit()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:137\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Projects/dogs-vs-cats/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner = tune_model(lenet5_v6, train_seq, val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58011696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tuner/lenet5_v6/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from tuner/lenet5_v6/tuner0.json\n",
      "1407/1407 [==============================] - 56s 40ms/step - loss: 0.0490 - f_score: 0.9833 - precision: 0.9931 - recall: 0.9755\n",
      "79/79 [==============================] - 3s 39ms/step - loss: 0.2270 - f_score: 0.9007 - precision: 0.9346 - recall: 0.9051\n",
      "train error =  0.01674330234527588\n",
      "test error =  0.0992971658706665\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "        lenet5_v6,\n",
    "        objective=\"val_loss\",\n",
    "        max_epochs=30,\n",
    "        hyperband_iterations=3,\n",
    "        factor=5,\n",
    "        directory='tuner',\n",
    "        project_name='lenet5_v6',\n",
    "    )\n",
    "lenet_v6_best_model = tuner.get_best_models()[0]\n",
    "print_errors(lenet_v6_best_model, train_seq, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3edc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0550 - f_score: 0.9778 - precision: 0.9771 - recall: 0.9808\n",
      "Epoch 1: val_loss improved from inf to 0.20775, saving model to dogs_vs_cats_lenet5_weights_1.h5\n",
      "1407/1407 [==============================] - 149s 105ms/step - loss: 0.0550 - f_score: 0.9778 - precision: 0.9771 - recall: 0.9808 - val_loss: 0.2077 - val_f_score: 0.9237 - val_precision: 0.9374 - val_recall: 0.9211 - lr: 1.7896e-04\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0587 - f_score: 0.9777 - precision: 0.9770 - recall: 0.9816\n",
      "Epoch 2: val_loss improved from 0.20775 to 0.18937, saving model to dogs_vs_cats_lenet5_weights_2.h5\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 0.0587 - f_score: 0.9777 - precision: 0.9770 - recall: 0.9816 - val_loss: 0.1894 - val_f_score: 0.9273 - val_precision: 0.9554 - val_recall: 0.9132 - lr: 1.7896e-04\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0469 - f_score: 0.9810 - precision: 0.9831 - recall: 0.9817\n",
      "Epoch 3: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 0.0469 - f_score: 0.9810 - precision: 0.9831 - recall: 0.9817 - val_loss: 0.2259 - val_f_score: 0.9227 - val_precision: 0.9460 - val_recall: 0.9117 - lr: 1.7896e-04\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0420 - f_score: 0.9851 - precision: 0.9847 - recall: 0.9870\n",
      "Epoch 4: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 149s 106ms/step - loss: 0.0420 - f_score: 0.9851 - precision: 0.9847 - recall: 0.9870 - val_loss: 0.1986 - val_f_score: 0.9124 - val_precision: 0.9449 - val_recall: 0.8927 - lr: 1.7896e-04\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0483 - f_score: 0.9815 - precision: 0.9821 - recall: 0.9839\n",
      "Epoch 5: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 0.0483 - f_score: 0.9815 - precision: 0.9821 - recall: 0.9839 - val_loss: 0.2110 - val_f_score: 0.9336 - val_precision: 0.9546 - val_recall: 0.9290 - lr: 1.7896e-04\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0357 - f_score: 0.9872 - precision: 0.9872 - recall: 0.9884\n",
      "Epoch 6: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 149s 106ms/step - loss: 0.0357 - f_score: 0.9872 - precision: 0.9872 - recall: 0.9884 - val_loss: 0.2680 - val_f_score: 0.9211 - val_precision: 0.8953 - val_recall: 0.9574 - lr: 1.7896e-04\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0374 - f_score: 0.9867 - precision: 0.9859 - recall: 0.9896\n",
      "Epoch 7: val_loss did not improve from 0.18937\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 3.57928714947775e-05.\n",
      "1407/1407 [==============================] - 149s 106ms/step - loss: 0.0374 - f_score: 0.9867 - precision: 0.9859 - recall: 0.9896 - val_loss: 0.3621 - val_f_score: 0.9004 - val_precision: 0.9597 - val_recall: 0.8644 - lr: 1.7896e-04\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0102 - f_score: 0.9965 - precision: 0.9968 - recall: 0.9965\n",
      "Epoch 8: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 0.0102 - f_score: 0.9965 - precision: 0.9968 - recall: 0.9965 - val_loss: 0.3614 - val_f_score: 0.9350 - val_precision: 0.9277 - val_recall: 0.9511 - lr: 3.5793e-05\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0012 - f_score: 0.9998 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 9: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 0.0012 - f_score: 0.9998 - precision: 0.9998 - recall: 0.9998 - val_loss: 0.4606 - val_f_score: 0.9353 - val_precision: 0.9444 - val_recall: 0.9369 - lr: 3.5793e-05\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 8.8179e-04 - f_score: 0.9997 - precision: 0.9996 - recall: 0.9997\n",
      "Epoch 10: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 8.8179e-04 - f_score: 0.9997 - precision: 0.9996 - recall: 0.9997 - val_loss: 0.4874 - val_f_score: 0.9365 - val_precision: 0.9445 - val_recall: 0.9401 - lr: 3.5793e-05\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0034 - f_score: 0.9994 - precision: 0.9995 - recall: 0.9994\n",
      "Epoch 11: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 0.0034 - f_score: 0.9994 - precision: 0.9995 - recall: 0.9994 - val_loss: 0.4775 - val_f_score: 0.9289 - val_precision: 0.9283 - val_recall: 0.9401 - lr: 3.5793e-05\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0018 - f_score: 0.9993 - precision: 0.9995 - recall: 0.9992\n",
      "Epoch 12: val_loss did not improve from 0.18937\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 7.158574589993805e-06.\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 0.0018 - f_score: 0.9993 - precision: 0.9995 - recall: 0.9992 - val_loss: 0.5148 - val_f_score: 0.9285 - val_precision: 0.9454 - val_recall: 0.9290 - lr: 3.5793e-05\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 0.0025 - f_score: 0.9995 - precision: 0.9996 - recall: 0.9993\n",
      "Epoch 13: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 0.0025 - f_score: 0.9995 - precision: 0.9996 - recall: 0.9993 - val_loss: 0.4680 - val_f_score: 0.9316 - val_precision: 0.9301 - val_recall: 0.9448 - lr: 7.1586e-06\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.5629e-04 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 14: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 1.5629e-04 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.4836 - val_f_score: 0.9303 - val_precision: 0.9341 - val_recall: 0.9385 - lr: 7.1586e-06\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 7.6043e-05 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 15: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 149s 106ms/step - loss: 7.6043e-05 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5073 - val_f_score: 0.9315 - val_precision: 0.9356 - val_recall: 0.9401 - lr: 7.1586e-06\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 4.4103e-05 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 16: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 4.4103e-05 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5404 - val_f_score: 0.9322 - val_precision: 0.9385 - val_recall: 0.9385 - lr: 7.1586e-06\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 2.3770e-05 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 17: val_loss did not improve from 0.18937\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.4317149179987611e-06.\n",
      "1407/1407 [==============================] - 148s 106ms/step - loss: 2.3770e-05 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5825 - val_f_score: 0.9342 - val_precision: 0.9401 - val_recall: 0.9401 - lr: 7.1586e-06\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.2920e-05 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 18: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 1.2920e-05 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.5936 - val_f_score: 0.9342 - val_precision: 0.9401 - val_recall: 0.9401 - lr: 1.4317e-06\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.0614e-05 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 19: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 149s 106ms/step - loss: 1.0614e-05 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6113 - val_f_score: 0.9350 - val_precision: 0.9415 - val_recall: 0.9401 - lr: 1.4317e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 7.8167e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 20: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 7.8167e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6362 - val_f_score: 0.9350 - val_precision: 0.9415 - val_recall: 0.9401 - lr: 1.4317e-06\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 5.2678e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 21: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 5.2678e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6676 - val_f_score: 0.9350 - val_precision: 0.9415 - val_recall: 0.9401 - lr: 1.4317e-06\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 3.3052e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 22: val_loss did not improve from 0.18937\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.863429926946992e-07.\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 3.3052e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7013 - val_f_score: 0.9354 - val_precision: 0.9415 - val_recall: 0.9401 - lr: 1.4317e-06\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 2.1585e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 23: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 2.1585e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7100 - val_f_score: 0.9337 - val_precision: 0.9400 - val_recall: 0.9385 - lr: 2.8634e-07\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.8719e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 24: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 1.8719e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7215 - val_f_score: 0.9337 - val_precision: 0.9400 - val_recall: 0.9385 - lr: 2.8634e-07\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.5666e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 25: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 1.5666e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7354 - val_f_score: 0.9337 - val_precision: 0.9400 - val_recall: 0.9385 - lr: 2.8634e-07\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.2827e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 26: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 1.2827e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7499 - val_f_score: 0.9337 - val_precision: 0.9400 - val_recall: 0.9385 - lr: 2.8634e-07\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.0446e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 27: val_loss did not improve from 0.18937\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 5.726859626520309e-08.\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 1.0446e-06 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7639 - val_f_score: 0.9337 - val_precision: 0.9400 - val_recall: 0.9385 - lr: 2.8634e-07\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 8.8539e-07 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 28: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 8.8539e-07 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7670 - val_f_score: 0.9337 - val_precision: 0.9400 - val_recall: 0.9385 - lr: 5.7269e-08\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 8.4833e-07 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 29: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 8.4833e-07 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7702 - val_f_score: 0.9337 - val_precision: 0.9400 - val_recall: 0.9385 - lr: 5.7269e-08\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 8.1191e-07 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 30: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 8.1191e-07 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7734 - val_f_score: 0.9337 - val_precision: 0.9400 - val_recall: 0.9385 - lr: 5.7269e-08\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 7.7665e-07 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 31: val_loss did not improve from 0.18937\n",
      "1407/1407 [==============================] - 149s 106ms/step - loss: 7.7665e-07 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7766 - val_f_score: 0.9337 - val_precision: 0.9400 - val_recall: 0.9385 - lr: 5.7269e-08\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 7.4237e-07 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 32: val_loss did not improve from 0.18937\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.1453719395149166e-08.\n",
      "1407/1407 [==============================] - 148s 105ms/step - loss: 7.4237e-07 - f_score: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7797 - val_f_score: 0.9337 - val_precision: 0.9400 - val_recall: 0.9385 - lr: 5.7269e-08\n",
      "Epoch 32: early stopping\n",
      "1032/1407 [=====================>........] - ETA: 14s - loss: 0.0357 - f_score: 0.9886 - precision: 0.9972 - recall: 0.9815"
     ]
    }
   ],
   "source": [
    "lenet_v6_best_model_trained = train_model(lenet_v6_best_model, train_seq, val_seq)\n",
    "print_errors(lenet_v6_best_model_trained, train_seq, test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5854ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-vs-cat",
   "language": "python",
   "name": "dog-vs-cat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
